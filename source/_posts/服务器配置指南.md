---
title: 深度学习服务器完整配置指南
tags: ML 
---

<!-- more -->

最近实验室配了一台深度学习服务器，服务器刚到时基本上只装了 ubuntu 操作系统，所以我也基本上是算从头配置了一台深度学习服务器。现将配置过程记录于此，以便帮助他人和方便交流。

首先，我的深度学习服务器的配置为：
 - ubuntu 14.04 操作系统，16.04 应该也是一样的
 - Anaconda3 集成的 python 环境，使用 conda 进行虚拟环境管理
 - jupyterhub 提供的 jupyter notebook 功能
 - cuda 9.0 + cudnn 7.1 + tensorflow 1.5.0

有了以上配置或环境，服务器就非常好用了。无论是用户虚拟环境管理，还是使用 jupyter notebook 都非常方便。

好了，接下来开始逐个介绍。

## 1. 网络配置
服务器刚到，第一步就是要进行网络配置。网络配置好之后，就可以将服务器放入机房，不用再忍受噪音，进行远程操作了。我这里的服务器是接入的校园网，因此也只介绍校园网下的网络配置，其他情况的同学需要去查一下资料配置。

### 1.1 接入校园网
首先，使用网线介入校园网，打通物理层面。注意不要接错网口，我之前因为接错网口，导致花了半下午时间找问题，可以说是很尴尬了。

接下来，使用 `ifconfig` 命令来查看网卡类型，`eth0` or `em1` 这种，我这里是 `em1`。然后修改 `/etc/network/interfaces` 如下：
```python
# This file describes the network interfaces available on your system
# and how to activate them. For more information, see interfaces(5).
# The loopback network interface
auto lo
iface lo inet loopback
# The primary network interface
auto em1
#iface em1 inet dhcp
iface em1 inet static
address xx.xx.xx.xx
netmask xxx.xxx.xxx.0
gateway xx.xx.xx.xxx
dns-nameservers xx.xx.x.xx
```
上面的配置其实就是给服务器设置一个静态 ip ，我们可以通过这个静态 ip 访问该服务器。然后配置网管，DNS 服务器什么的。和 windows 下配置类似，实验室用过有线的应该都懂。

配置好之后，就可以连接内网了。使用 `ping 10.xx.xxx.xxx（你的校园网内网 ip 地址）` 来检查是否能连内网。

注意，我这里记录的是我们学校的校园网接入方式，我不清楚不同学校的校园网接入方式是否相同，需要大家搞清楚。

### 1.2 镜像源配置
#### 1.2.1 更改 apt-get 镜像源
将服务器只放在校园网环境下，这样做有两个好处：

1. 安全
2. 校园网速度非常快

但很明显，如果只连校园网，我们将无法下载日常使用的软件或者包。但还好，这个问题很好解决，只需要修改镜像源即可。

我们在使用 `apt-get install` 命令时，会向外网发送请求，下载我们需要的软件。而修改镜像源之后，则会转而向我们指定的网站发送请求。这里我们使用的是清华的镜像源，清华的镜像源使用校园网内网即可访问，非常适合我们这种校园网的服务器。

首先，把 `/etc/apt/source.list` 文件备份，然后将 `source.list` 的内容修改如下（具体内容和 linux 发行版本有关，具体见 [Ubuntu 镜像使用帮助](https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/)）：

```python
# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse
# 预发布软件源，不建议启用
# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse
```

然后就可以在内网下使用 `apt-get install` 命令了。

### 1.2.2 更改 pip 和 conda 源
使用 pip 或者 conda 安装 python 模块非常方便，但是我们只接入了校园网，所以需要更改一下 pip 和 anaconda 的源。

pip 更改方式如下：
修改 ~/.pip/pip.conf（没有就创建一个），内容如下：
```python
 [global]
 index-url = https://pypi.tuna.tsinghua.edu.cn/simple
```

conda 更改方式如下：
```python
# 命令行输入如下命令
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --set show_channel_urls yes
```

修改之后，可以测试一下速度，我这里能上 `10M/s`，还是非常快的。

### 1.2.3 外网访问
如果是在需要访问外网，可以使用 vpn 连接到外网。我这里使用的是校内流传的一个软件，不同学校不同。

使用 `sudo dpkg -i xl2tpd_1.2.5%2Bzju-1_amd64.deb` 安装之后，按照下面方式配置：
```python
# 配置用户名和密码
$ sudo vpn-connect -c
Configure L2TP VPN for ZJU.
# 这里的Username是你的学号，后面的@代表你是10/30/50包月。
Username: 216....@10
Password: 你的密码
# 配置完成，使用这个命令开启连接
$ sudo vpn-connect
#连接成功，可以ping一下百度，看是否能连外网了
$ ping www.baidu.com
# 重连，断开等，可以使用下面的命令查看
$ vpn-connect -h
```

以上，基本上就是网络配置的内容了。以上配置好后，基本上就够一个服务器使用了，毕竟，作为计算型服务器，平时使用最多的也就是使用 ssh 远程访问和使用 pip 了。

## 2. 环境配置
这一节主要介绍下 python 环境配置。由于服务器需要多用户使用，因此虚拟环境必不可少。每个用户都使用自身的 python 虚拟环境，可以避免模块版本冲突等问题。此外，jupyter notebook 作为一个方便的 python 交互式环境，能在客户端使用它并且支持多用户使用，也是需要进行配置的。

### 2.1 python 虚拟环境
python 环境我们使用 Anaconda 进行配置。Anaconda 集成了 python 环境和常用的模块，可以帮我们省很多功夫。

使用 `sudo apt-get install anaconda3` 安装 Anaconda3。也可以去网上下载 anaconda3 的安装包，上传到服务器之后进行安装。Anyway，只要能够成功安装就行，这一步很简单。

之后，可以在命令行输入`python` 和 `conda` 来查看是否安装成功。

最后需要修改全局变量，因为此时，只有 root 用户能够使用该环境，其他用户无法正常使用。修改方式如下：
```python
echo 'PATH=/usr/lib/anaconda/bin:$PATH' >> /etc/profile.d/anaconda.sh
source /etc/profile
```
这样，所有用户都可以使用 Anaconda 了，也可以使用 conda 建立虚拟环境了。

建议在使用服务器进行开发时，每位用户都在自己的 python 虚拟环境下进行开发，不要在全局安装 python 的包和库。建立虚拟环境的方式如下：
```python
list all env:
    conda info --env
create a simple virtual env:
    conda create -n MyEnvName python=3*
delete virtual env:
    conda env remove -n MyEnvName
```
建立完成后，使用 `source activate MyEnvName` 进入虚拟环境，使用 `source deactivate` 推出虚拟环境。

需要注意的是，在自己的虚拟环境下，使用 pip 安装 python 模块，还是安装到全局中的，需要使用 `conda -n myEnv install pip` 或者在虚拟环境下使用 `conda install pip` 来安装虚拟环境中的pip，这样在虚拟环境中使用pip就能将包安装到虚拟环境中了。

### 2.2 jupyter notebook 配置
在服务器开启 jupyter notebook 服务，可以在客户端使用浏览器登陆服务器的 jupyter notebook，但是如果多用户同时使用，就需要每个用户都进行配置然后开启服务，非常麻烦。

Jupyterhub 是一组进程，使用 JupyterHub 可以为组中的每个人分别提供单个用户的 Jupyter Notebook 服务器。具体使用方式见[JupyterHub](https://jupyterhub.readthedocs.io/en/0.7.0/quickstart.html)。

## 3. 深度学习环境：cuda9.0 + cudnn7.1 + tensorflow 1.5.0
我安装深度学习环境主要是为了使用 tensorflow, 但不同版本的 tensorflow 需要安装不同版本的 cuda ，所以需要先明确自己使用的 tensorflow 版本。我要使用 tensorflow 1.5.0 ，所以选择安装 cuda9.0 + cudnn7.1。

### 3.1 什么是 cuda 和 cudnn
CUDA 是由 NVIDIA 推出的一种集成技术，用于 GPU 的并行计算。

CUDA 的作用，是与通用程序对接。比如，我们使用 python 写的程序，将数据和运算逻辑准备好之后，需要调用 CUDA 库提供的函数来传递给 CUDA，CUDA 再调用显卡驱动对 CUDA 程序进行编译，然后再将编译好的程序和数据传送给 GPU 进行运算。

而 cuDNN 是用于深度神经网络的 GPU 加速计算库。它可以将卷积神经网路的计算变换为对 GPU 更友好的矩阵运算，可以有效提高整个网络的训练速度。

要使用 tensorflow 的 GPU 版本，我们需要安装 CUDA 和 cuDNN。

### 3.2 安装 cuda9.0 + cudnn7.1
#### 3.2.1 安装前
1. 首先，确保你的电脑上有 CUDA 支持的 GPU 硬件。

在终端下，输入 `lspci | grep -i nvidia` 来查看。如果有 GPU 安装，会显示结果。

2. 确保系统中安装了 gcc

使用 `gcc --version` 来查看 gcc 版本，确保系统中已经安装了 gcc 。

3. 验证系统是否安装了正确的内核头文件和开发包

使用 `uname -r` 来查看系统的核版本。
使用 `$ sudo apt-get install linux-headers-$(uname -r)` 来安装当前正在运行的内核的内核头文件和开发包。

4. 下载 CUDA

CUDA 可以在 [NVIDIA 网站](https://developer.nvidia.com/cuda-downloads) 下载，选择自己相应的选项后，就可以下载了。我这里下载的是 CUDA9.0 的 runfile(local) 。 然后上传到服务器。

#### 3.2.2 安装 cuda
到之前我们下载的 runfile 文件目录下，运行如下命令：
```
$ sudo sh cuda_<version>_linux.run
```
进行安装。

安装程序会提示如下内容：

 - EULA Acceptance：接受协议即可
 - CUDA Driver installation：如果你已经装好了 nvidia 显卡驱动，这里需要选择 `n` 。注意，你的 nvidia 显卡驱动版本需要适配 CUDA 版本
 - CUDA Toolkit installation，location，and /usr/local/cuda symbolic link：这里全选 `y` 和默认即可
 - CUDA Samples installation and location：这个最好安装一下，后续可以用于验证 CUDA 是否安装正确

安装完成后，重启系统。

#### 3.2.3 安装后
重启系统后，需要修改环境变量。具体操作如下：
```
$ export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}
$ export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64\
                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
```

至此，CUDA 安装完毕。接下来我们验证一下 CUDA 是否安装成功。

1. 检查 /dev/ 目录下是否存在以 nvidia* 开头的多个文件
2. 检查 CUDA Toolkit 是否安装成功

    终端输入 `nvcc -V` 会输出 CUDA 版本信息
3. 编译 Samples 例子

    进入到 Samples 安装目录，终端输入 `make` 进行编译
4. 编译完成后测试

    进入 `bin/x86_64/linux/release/` 目录。
    
    运行 deviceQuery 程序： `$ sudo ./deviceQuery` ，查看输出结果，最后一行显示 `Result = PASS` 表示通过测试。

    运行 bandwidthTest 程序： `$ sudo ./bandwidthTest`, 查看输出结果，最后一行显示 `Result = PASS` 表示通过测试。

如果以上均没有问题，则说明 CUDA 安装成功。

#### 3.2.4 安装 cudnn
cudnn 的安装非常简单，只有以下几步：

1. 下载 cudnn 安装包

    前往 [NVIDIA cuDNN home page](https://developer.nvidia.com/cudnn), 注册账号之后，下载 cudnn 压缩包（tgz格式）。注意，win10 操作系统在下载 tgz 格式文件时，会将后缀名转变为 .solita* ，这个文件在 linux 下也能解压，但是会报错，实践证明，解压出的文件也是不能用的，因此，建议在 linux 系统或 mac os 下下载上述压缩包。然后上传到服务器。

2. 解压压缩包

    输入命令：`$ tar -xzvf cudnn-9.0-linux-x64-v7.tgz`，会在当前目录下生成一个 cuda/ 目录。

3. copy 以下文件到 CUDA Toolkit 目录下

    终端输入以下命令：
    ```
    $ sudo cp cuda/include/cudnn.h /usr/local/cuda/include
    $ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
    $ sudo chmod a+r /usr/local/cuda/include/cudnn.h
    $ sudo chmod a+r /usr/local/cuda/lib64/libcudnn*
    ```

经过以上三步，cudnn 也安装好了，接下来只需要安装 tensorflow 了！


### 3.3 安装 tensorflow
最简单的方式当然是使用 pip 进行安装了！

在终端下输入 `pip install tensorflow-gpu==1.5.0` 即可。

注意我们安装的是 gpu 版本，所以一定要是 `tensorflow-gpu`，等号后面代表我们想要安装的 tensorflow 版本。

安装成功后，终端输入 `python` 进入 python 环境，运行以下代码，若运行成功，则说明我们的 tensorflow 环境也就配置成功了！

```python
>>> import tensorflow
```

## 4. 总结
要配置及维护好一个深度学习服务器还有很长的路要走。比如 ACL 文件权限管理系统，用户权限管理，shell script 学习等。

我这里记录的内容，能够让服务器实现多用户深度学习开发，能对于现在的实验室已经够用了，之后后面的内容，如果有需要会继续学习。

以上内容，最耗费时间的就是 CUDA 和 cudnn 环境的配置了。刚开始偷懒，想跟着中文博客去安装，后来看了数十篇博客，中间碰到各种问题又不断 Google ，解决了一个问题又出现新的问题，真的非常心累。 后来跟着 NVIDIA 的官网教程，重新安装了一遍，总算是成功了。

这让我明白，无论是学习新东西也好，使用一个新工具也好，最好的资料一定是官方编写的。网上铺天盖地的博客，无非是对论文或者官方教程的二次加工。所以一定不要偷懒，耐着性子去琢磨英文版的官方教程，一定是没有问题的！

我这篇博客其实是对我配置深度学习服务器的梳理，也是对查找的各种资料的总结和对官方教程的二次加工。前面的内容应该很好配置。 如果 CUDA 或 cudnn 的安装出了问题，建议仔细研读 NVIDIA 的官方教程。

[Installation Guide Linux :: CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html)

[cuDNN Installation Guide :: Deep Learning SDK Documentation](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/)